{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "The dataset consists of detection *events*, wherein a variable number of particles come into contact with the detector's cells. The location of these impacts are called *hits*, and there are likewise a variable number of them per particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 samples.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('tracks.pickle', 'rb') as f:\n",
    "    samples = pickle.load(f)\n",
    "\n",
    "print(\"Loaded {} samples.\".format(len(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "Each sample contains a set of hits, and each hit contains the following information:\n",
    "\n",
    "* *x,y,z* coordinates\n",
    "* Cell count and impact magnitude\n",
    "* A learned hit embedding, output from the previous graph creation stage\n",
    "* Ground truth cluster ID, denoting the particle which created the hit\n",
    "\n",
    "Additionally, samples contain graphs as output from the previous stage which aims to connect hits created by the same particle. The two graphs included are\n",
    "\n",
    "* A predicted graph, the raw output from the graph building stage\n",
    "* An augmented graph, which contains the predicted graph, plus any connections missed between hits created by the same particle. This is used in the GNN's loss function.\n",
    "\n",
    "### Visualizations\n",
    "\n",
    "Choosing a sample to explore, one can see how the embedding differs from the raw features for graph creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_clusters(x,y,pid):\n",
    "    for g in np.unique(pid):\n",
    "        i = np.where(pid == g)\n",
    "        plt.scatter(x[i],y[i], label=g)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "hits = samples[1]['hits']\n",
    "xyz = hits['xyz']\n",
    "emb = hits['emb']\n",
    "pid = hits['particle_id']\n",
    "\n",
    "# Hit coordinates\n",
    "plot_clusters(xyz[:,2], np.sqrt(xyz[:,0]**2 + xyz[:,1]**2), pid)\n",
    "\n",
    "# Emb coordinates\n",
    "plot_clusters(emb[:,0], emb[:,1], pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the embedding will lead to superior clustering as compared with the raw *x,y,z* positions. However, this embedding incorporates information from only each hit individually. With a GNN, one can create node embeddings which incorporate information from the hit's neighborhood. As we will see, this allows for superior embeddings and thus improved performance in clustering.\n",
    "\n",
    "# Model\n",
    "\n",
    "The GNN model chosen is a simple message-passing architecture. One layer concatenates each node's features with an aggregation of the node's neighborhood, before applying a transformation via a fully-connected neural network layer.\n",
    "\n",
    "The output of the model is a set of node embeddings, where this new embedding has the same goal as in the graph building stage: according to some distance metric, node pairs whose hits belong to the same particle should be close, and otherwise they should be far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                   nb_hidden_gnn,\n",
    "                   nb_layer,\n",
    "                   nb_hidden_kernel,\n",
    "                   nb_kernel,\n",
    "                   input_dim):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        # Construct first layer\n",
    "        gnn_layers = [GNN_Layer(input_dim,\n",
    "                                nb_hidden_gnn,\n",
    "                                nb_kernel,\n",
    "                                nb_hidden_kernel,\n",
    "                                apply_norm=True,\n",
    "                                softmax=False)]\n",
    "\n",
    "        # Construct additional layers\n",
    "        for _ in range(nb_layer-1):\n",
    "            gnn_layers.append(GNN_Layer(nb_hidden_gnn,\n",
    "                                        nb_hidden_gnn,\n",
    "                                        nb_kernel,\n",
    "                                        nb_hidden_kernel))\n",
    "        self.layers = nn.ModuleList(gnn_layers)\n",
    "\n",
    "        self.final_emb = nn.Linear(nb_hidden_gnn, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, g):\n",
    "        if torch.cuda.is_available():\n",
    "            g.ndata['feat'] = g.ndata.pop('feat').to('cuda', non_blocking=True)\n",
    "        feat = g.ndata['feat']\n",
    "        emb = g.ndata.pop('feat')\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            emb = layer(g, emb)\n",
    "        emb = self.sigmoid(self.final_emb(emb))\n",
    "        g.ndata['feat'] = feat\n",
    "        return emb.squeeze(1)\n",
    "\n",
    "    def weighted_msg(e):\n",
    "        return {'msg': e.src['feat'] * e.data['e']}\n",
    "\n",
    "\n",
    "class GNN_Layer(nn.Module):\n",
    "    def __init__(self,\n",
    "               input_dim,\n",
    "               nb_hidden_gnn,\n",
    "               nb_kernel,\n",
    "               nb_hidden_kernel,\n",
    "               apply_norm=True,\n",
    "               softmax=False):\n",
    "        super(GNN_Layer, self).__init__()\n",
    "\n",
    "        if softmax:\n",
    "            self.kernel = MLP_Kernel_DGL_Softmax(input_dim, nb_hidden_kernel)\n",
    "        else:\n",
    "            self.kernel = MLP_Kernel_DGL(input_dim, nb_hidden_kernel)\n",
    "\n",
    "        self.gconv = DGL_Convolution(input_dim, nb_hidden_gnn)\n",
    "        self.bn = nn.BatchNorm1d(input_dim,momentum=0.10) if apply_norm else None\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        # maybe apply normalization\n",
    "        if self.bn is not None:\n",
    "            features = self.bn(features)\n",
    "        g.ndata['feat'] = features\n",
    "\n",
    "        # set edge weights for this layer\n",
    "        g = self.kernel(g)\n",
    "        \n",
    "        # send weighted messages and apply graph convolution to nodes\n",
    "        g.send_and_recv(g.edges(),\n",
    "                        message_func=weighted_msg,\n",
    "                        reduce_func=dgl.function.sum(msg='msg', out='agg_msg'),\n",
    "                        apply_node_func=self.gconv)\n",
    "        g.ndata.pop('feat')\n",
    "        g.ndata.pop('agg_msg')\n",
    "        return g.ndata.pop('emb')\n",
    "\n",
    "class DGL_Convolution(nn.Module):\n",
    "    def __init__(self,\n",
    "               input_dim,\n",
    "               nb_hidden_gnn):\n",
    "        super(DGL_Convolution, self).__init__()\n",
    "        self.weights = nn.Linear(2*input_dim, nb_hidden_gnn)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, n):\n",
    "        feats = n.data['feat']\n",
    "        agg_msg = n.data['agg_msg']\n",
    "        node_feats = torch.cat((feats, agg_msg), dim=1)\n",
    "        emb = self.weights(node_feats)\n",
    "        emb = self.act(emb)\n",
    "        return {'emb':emb}\n",
    "\n",
    "\n",
    "class MLP_Kernel_DGL(nn.Module):\n",
    "    def __init__(self, nb_input, nb_hidden_gnn, nb_output=1, nb_layer=1):\n",
    "        super(MLP_Kernel_DGL, self).__init__()\n",
    "        layers = [nn.Linear(nb_input*2, nb_hidden_gnn)]\n",
    "        for _ in range(nb_layer-1):\n",
    "            layers.append(nn.Linear(nb_hidden_gnn, nb_hidden_gnn))\n",
    "        layers.append(nn.Linear(nb_hidden_gnn, nb_output))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.act2 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, g):\n",
    "        g.apply_edges(self.mlp)\n",
    "        return g\n",
    "\n",
    "    def mlp(self, e):\n",
    "        # Gather features from all relevant node pairs\n",
    "        src = e.src['feat']\n",
    "        dst = e.dst['feat']\n",
    "        e_feats = torch.cat((src,dst),dim=1)\n",
    "        \n",
    "        # Apply MLP layers to node pairs\n",
    "        for l in self.layers[:-1]:\n",
    "            e_feats = self.act1(l(e_feats))\n",
    "        \n",
    "        # Apply final output with sigmoid\n",
    "        e_feats = self.layers[-1](e_feats)\n",
    "        e_feats = self.act2(e_feats)\n",
    "        return {'e':e_feats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering model\n",
    "\n",
    "class Hier_GNN(nn.Module):\n",
    "    def __init__(self, nb_input, nb_hidden, nb_layer):\n",
    "        super(Hier_GNN, self).__init__()\n",
    "        self.split_gnn = GNN(nb_hidden, nb_layers, nb_hidden, 1, nb_input)\n",
    "        self.stop_gnn  = GNN(nb_hidden, nb_layers, nb_hidden, 1, nb_input)\n",
    "    \n",
    "    # Training\n",
    "    def forward(self, g_input, truth, depth):\n",
    "        stop_graph, stop_loss = self.stop(g_input, truth[depth])\n",
    "        if stop_graph is None:\n",
    "            return 0, stop_loss\n",
    "        split_graph, split_loss = self.split(stop_graph, truth[depth])\n",
    "        \n",
    "        stop_loss_rec, split_loss_rec = self(split_graph, truth, depth+1)\n",
    "        return stop_loss + stop_loss_rec, split_loss + split_loss_rec\n",
    "    \n",
    "    def stop(self, g_input, truth):\n",
    "        assert torch.equal(g_input.ndata['hit_id'], torch.LongTensor(truth[0]))\n",
    "        stop_pred = self.stop_gnn(g_input)\n",
    "        stop_truth = torch.FloatTensor(truth[2])\n",
    "        stop_loss = nn.functional.binary_cross_entropy(stop_pred, stop_truth)\n",
    "        if sum(stop_truth) < 1:\n",
    "            return g_input, stop_loss\n",
    "        elif int(sum(stop_truth)) == len(stop_truth):\n",
    "            return None, stop_loss\n",
    "        \n",
    "        g_input.ndata['stop'] = stop_truth\n",
    "        should_stop = list(dgl.mean_nodes(g_input, 'stop').numpy())\n",
    "        \n",
    "        g = dgl.unbatch(g_input)\n",
    "        keep = []\n",
    "        for i, gt in enumerate(should_stop):\n",
    "            if gt < 0.5:\n",
    "                keep.append(g[i])\n",
    "        g = dgl.batch(keep)\n",
    "        return g, stop_loss\n",
    "    \n",
    "    def split(self, g_input, truth):\n",
    "        where_keep = (1-truth[2]).astype(bool)\n",
    "        hit_ids = truth[0][where_keep]\n",
    "        assert torch.equal(g_input.ndata['hit_id'], torch.LongTensor(hit_ids))\n",
    "        split_pred = self.split_gnn(g_input)\n",
    "        split_truth = torch.FloatTensor(truth[1][where_keep])\n",
    "        split_loss_a = nn.functional.binary_cross_entropy(split_pred, split_truth, reduction='none')\n",
    "        split_loss_b = nn.functional.binary_cross_entropy(split_pred, 1-split_truth, reduction='none')\n",
    "        \n",
    "        # Loss should respect divide, not direction\n",
    "        g_input.ndata['loss_a'] = split_loss_a\n",
    "        g_input.ndata['loss_b'] = split_loss_b\n",
    "        loss_a = dgl.mean_nodes(g_input, 'loss_a')\n",
    "        loss_b = dgl.mean_nodes(g_input, 'loss_b')\n",
    "        split_loss = torch.min(loss_a, loss_b).mean()\n",
    "        \n",
    "        g_input.ndata['split'] = split_truth\n",
    "        graphs = dgl.unbatch(g_input)\n",
    "        new_graphs = []\n",
    "        for g in graphs:\n",
    "            g_l, g_r = self.split_one_graph(g)\n",
    "            new_graphs += [g_l, g_r]\n",
    "        split_graph = dgl.batch(new_graphs)\n",
    "        return split_graph, split_loss\n",
    "    \n",
    "    def split_one_graph(self, g):\n",
    "        truth = g.ndata['split']\n",
    "        go_left = (truth==0).nonzero().squeeze(1)\n",
    "        go_right = truth.nonzero().squeeze(1)\n",
    "        g_l = g.subgraph(list(go_left.numpy()))\n",
    "        g_r = g.subgraph(list(go_right.numpy()))\n",
    "        g_l.copy_from_parent()\n",
    "        g_r.copy_from_parent()\n",
    "        if len(go_left) == 0:\n",
    "            g_l = None\n",
    "        if len(go_right) == 0:\n",
    "            g_r = None\n",
    "        return g_l, g_r\n",
    "    \n",
    "    \n",
    "    # Inference\n",
    "    def build_clusters(self, g_input, depth, max_depth):\n",
    "        print('\\n',depth)\n",
    "        if depth == 0:\n",
    "            self.next_cluster = 0\n",
    "            self.clusters = []\n",
    "        if depth == max_depth:\n",
    "            hit_ids = g_input.ndata['hit_id']\n",
    "            clusters = np.array([self.next_cluster]*len(hit_ids))\n",
    "            self.clusters.append((hit_ids.numpy(), clusters))\n",
    "            return self.organize_clusters(self.clusters)\n",
    "        g = self.stop_inference(g_input)\n",
    "        if g is None:\n",
    "            return self.organize_clusters(self.clusters)\n",
    "        else:\n",
    "            g = self.split_inference(g_input)\n",
    "            return self.build_clusters(g, depth+1, max_depth)\n",
    "        \n",
    "    def stop_inference(self, g_input):\n",
    "        stop_pred = self.stop_gnn(g_input)\n",
    "        \n",
    "        g_input.ndata['stop'] = stop_pred\n",
    "        should_stop = list(dgl.mean_nodes(g_input, 'stop').numpy())\n",
    "        print(\"should stop\", should_stop)\n",
    "        \n",
    "        g = dgl.unbatch(g_input)\n",
    "        keep = []\n",
    "        stop = []\n",
    "        for i, gt in enumerate(should_stop):\n",
    "            if gt < 0.5:\n",
    "                keep.append(g[i])\n",
    "            else:\n",
    "                stop.append(g[i])\n",
    "        \n",
    "        if len(stop)==0:\n",
    "            return g_input\n",
    "        \n",
    "        # Assign cluster labels\n",
    "        for stopped in stop:\n",
    "            hit_ids = stopped.ndata['hit_id']\n",
    "            clusters = np.array([self.next_cluster]*len(hit_ids))\n",
    "            self.clusters.append((hit_ids.numpy(), clusters))\n",
    "            self.next_cluster += 1\n",
    "        \n",
    "        if len(keep) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            g = dgl.batch(keep)\n",
    "            return g\n",
    "        \n",
    "    def split_inference(self, g_input):\n",
    "        split_pred = self.split_gnn(g_input)\n",
    "\n",
    "        g_input.ndata['split'] = split_pred.round().to(torch.long)\n",
    "        graphs = dgl.unbatch(g_input)\n",
    "        new_graphs = []\n",
    "        for g in graphs:\n",
    "            g_l, g_r = self.split_one_graph(g)\n",
    "            if g_l is not None:\n",
    "                new_graphs.append(g_l)\n",
    "            if g_r is not None:\n",
    "                new_graphs.append(g_r)\n",
    "        split_graph = dgl.batch(new_graphs)\n",
    "        return split_graph\n",
    "    \n",
    "    def organize_clusters(self, clusters):\n",
    "        hit_ids = [c[0] for c in clusters]\n",
    "        cluster_ids = [c[1] for c in clusters]\n",
    "        \n",
    "        hit_ids = np.concatenate(hit_ids)\n",
    "        cluster_ids = np.concatenate(cluster_ids)\n",
    "        \n",
    "        return cluster_ids[np.argsort(hit_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset, Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "def get_edge_indices(edges):\n",
    "    edge_pairs = []\n",
    "    for i, neighbors in enumerate(edges):\n",
    "        for e_idx in neighbors:\n",
    "            edge_pairs.append([i,e_idx])\n",
    "    return edge_pairs\n",
    "\n",
    "def get_true_edge_values(pred_edge_idx, true_edges):\n",
    "    values = [0] * len(pred_edge_idx)\n",
    "    for i, (src, dst) in enumerate(pred_edge_idx):\n",
    "        if dst in true_edges[src]:\n",
    "            values[i] = 1\n",
    "    return values\n",
    "\n",
    "class TrackML_Dataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s = self.samples[index]\n",
    "        \n",
    "        hits = s['hits']\n",
    "        xyz  = hits['xyz']\n",
    "        emb  = hits['emb']\n",
    "        pid  = torch.FloatTensor(hits['particle_id'])\n",
    "        weight  = torch.FloatTensor(hits['weight'])\n",
    "        hits = torch.FloatTensor(np.concatenate((xyz, emb), axis=1))\n",
    "        \n",
    "\n",
    "        graphs = s['graphs']\n",
    "        pred_edges = graphs['pred']\n",
    "        loss_edges = graphs['loss']\n",
    "        true_edges = graphs['true']\n",
    "    \n",
    "        pred_edge_idx = get_edge_indices(pred_edges)\n",
    "        \n",
    "        # Build inference graph\n",
    "        g_input = dgl.DGLGraph()\n",
    "        g_input.add_nodes(len(hits))\n",
    "        src, dst = tuple(zip(*pred_edge_idx))\n",
    "        g_input.add_edges(src, dst)\n",
    "        g_input.ndata['feat'] = hits\n",
    "        g_input.ndata['pid'] = pid\n",
    "        g_input.ndata['weight'] = weight\n",
    "\n",
    "        g_input.set_n_initializer(dgl.init.zero_initializer)\n",
    "        g_input.set_e_initializer(dgl.init.zero_initializer)\n",
    "\n",
    "        # Get hierarchy data\n",
    "        hier = s['hier']\n",
    "        g_input.ndata['hit_id'] = torch.LongTensor(hier[0][0])\n",
    "\n",
    "        return g_input, hier\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "def trackml_collate(sample):\n",
    "    g_input = [s[0] for s in sample]\n",
    "    g_input = dgl.batch(g_input)\n",
    "    \n",
    "    hier   = [s[1] for s in sample]\n",
    "    assert(len(hier) == 1)\n",
    "\n",
    "    return g_input, hier[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# PARAMETERS\n",
    "batch_size = 1\n",
    "nb_hidden = 32\n",
    "nb_layers = 3\n",
    "learn_rate = 0.001\n",
    "\n",
    "dataset = TrackML_Dataset(samples)\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        collate_fn=trackml_collate, \n",
    "                        drop_last=True, \n",
    "                        shuffle=True,\n",
    "                        num_workers=0)\n",
    "\n",
    "net = Hier_GNN(6, nb_hidden, nb_layers)\n",
    "optim = torch.optim.Adamax(net.parameters(), lr=learn_rate)\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on 100 samples\n",
      "    1  Loss: 6.67  Split: 3.78  Stop: 2.90\n",
      "   21  Loss: 6.56  Split: 3.85  Stop: 2.72\n",
      "   41  Loss: 6.43  Split: 3.83  Stop: 2.60\n"
     ]
    }
   ],
   "source": [
    "def get_emb_for_loss(e):\n",
    "    src = e.src['emb']\n",
    "    dst = e.dst['emb']\n",
    "    truth = e.data['truth']\n",
    "    pred_dst = nn.functional.pairwise_distance(src, dst)\n",
    "    true_dst = truth*2 -1\n",
    "    loss = nn.functional.hinge_embedding_loss(pred_dst, true_dst, reduction='none')\n",
    "    return {'loss':loss, 'pred_dst':pred_dst, 'true_dst':true_dst}\n",
    "\n",
    "def score_dist_accuracy(pred, true):\n",
    "    pred = pred.round()\n",
    "    pred[pred!=0] = 1\n",
    "    pred = 1-pred\n",
    "    correct = pred==true\n",
    "    nb_correct = correct.sum()\n",
    "    nb_total = true.size(0)\n",
    "    score = float(nb_correct.item()) / nb_total\n",
    "    return score\n",
    "\n",
    "def train_one_epoch(net, batch_size, optimizer, train_loader):\n",
    "    net.train()\n",
    "\n",
    "    nb_batch = len(train_loader)\n",
    "    nb_train = nb_batch * batch_size\n",
    "    epoch_score = 0\n",
    "    epoch_loss  = 0\n",
    "    epoch_split = 0\n",
    "    epoch_stop  = 0\n",
    "\n",
    "    print(\"\\nTraining on {} samples\".format(nb_train))\n",
    "    for i, (g_input, hier) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        f = g_input.ndata['feat']\n",
    "\n",
    "        stop_loss, split_loss = net(g_input, hier, 0)\n",
    "\n",
    "        loss = stop_loss + split_loss\n",
    "        score = 0\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_score += score * 100\n",
    "        epoch_loss  += loss.item()\n",
    "        epoch_split += split_loss.item()\n",
    "        epoch_stop  += stop_loss.item()\n",
    "\n",
    "        nb_proc = (i+1) * batch_size\n",
    "        if (((i) % (nb_batch//5)) == 0):\n",
    "            print(\"  {:3d}  Loss: {:.2f}  Split: {:1.2f}  Stop: {:1.2f}\".format(\n",
    "                                nb_proc, epoch_loss/(i+1), epoch_split/(i+1), epoch_stop/(i+1)))\n",
    "    return epoch_loss / nb_batch, epoch_score / nb_batch\n",
    "\n",
    "for i in range(4):\n",
    "    train_one_epoch(net, batch_size, optim, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed samples\n",
    "clusters = []\n",
    "pid = []\n",
    "weight = []\n",
    "net.eval()\n",
    "with torch.autograd.no_grad():\n",
    "    for i, (g_input, hier) in enumerate(dataloader):\n",
    "        pid.append(g_input.ndata['pid'])\n",
    "        weight.append(g_input.ndata['weight'])\n",
    "        c = net.build_clusters(g_input, 0, max_depth=10)\n",
    "        clusters.append(c)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score samples\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TrackML scoring metric (by Sabrina Amrouche, David Rousseau, Moritz Kiehn, Ilija Vukotic)\n",
    "\"\"\"\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "def _analyze_tracks(truth, submission):\n",
    "    particles_nhits = truth['particle_id'].value_counts(sort=False)\n",
    "    total_weight = truth['weight'].sum()\n",
    "    event = pandas.merge(truth[['hit_id', 'particle_id', 'weight']],\n",
    "                         submission[['hit_id', 'track_id']],\n",
    "                         on=['hit_id'], how='left', validate='one_to_one')\n",
    "    event.drop('hit_id', axis=1, inplace=True)\n",
    "    event.sort_values(by=['track_id', 'particle_id'], inplace=True)\n",
    "\n",
    "\n",
    "    tracks = []\n",
    "    rec_track_id = -1\n",
    "    rec_nhits = 0\n",
    "    cur_particle_id = -1\n",
    "    cur_nhits = 0\n",
    "    cur_weight = 0\n",
    "    maj_particle_id = -1\n",
    "    maj_nhits = 0\n",
    "    maj_weight = 0\n",
    "\n",
    "    for hit in event.itertuples(index=False):\n",
    "        if (rec_track_id != -1) and (rec_track_id != hit.track_id):\n",
    "            if maj_nhits < cur_nhits:\n",
    "                maj_particle_id = cur_particle_id\n",
    "                maj_nhits = cur_nhits\n",
    "                maj_weight = cur_weight\n",
    "            tracks.append((rec_track_id, rec_nhits, maj_particle_id,\n",
    "                particles_nhits[maj_particle_id], maj_nhits,\n",
    "                maj_weight / total_weight))\n",
    "\n",
    "        if rec_track_id != hit.track_id:\n",
    "            rec_track_id = hit.track_id\n",
    "            rec_nhits = 1\n",
    "            cur_particle_id = hit.particle_id\n",
    "            cur_nhits = 1\n",
    "            cur_weight = hit.weight\n",
    "            maj_particle_id = -1\n",
    "            maj_nhits = 0\n",
    "            maj_weights = 0\n",
    "            continue\n",
    "\n",
    "        rec_nhits += 1\n",
    "\n",
    "        if cur_particle_id != hit.particle_id:\n",
    "            if maj_nhits < cur_nhits:\n",
    "                maj_particle_id = cur_particle_id\n",
    "                maj_nhits = cur_nhits\n",
    "                maj_weight = cur_weight\n",
    "            cur_particle_id = hit.particle_id\n",
    "            cur_nhits = 1\n",
    "            cur_weight = hit.weight\n",
    "        else:\n",
    "            cur_nhits += 1\n",
    "            cur_weight += hit.weight\n",
    "\n",
    "    if maj_nhits < cur_nhits:\n",
    "        maj_particle_id = cur_particle_id\n",
    "        maj_nhits = cur_nhits\n",
    "        maj_weight = cur_weight\n",
    "    tracks.append((rec_track_id, rec_nhits, maj_particle_id,\n",
    "        particles_nhits[maj_particle_id], maj_nhits, maj_weight / total_weight))\n",
    "\n",
    "    cols = ['track_id', 'nhits',\n",
    "            'major_particle_id', 'major_particle_nhits',\n",
    "            'major_nhits', 'major_weight']\n",
    "    return pandas.DataFrame.from_records(tracks, columns=cols)\n",
    "\n",
    "def score_event(truth, submission):\n",
    "    tracks = _analyze_tracks(truth, submission)\n",
    "    purity_rec = np.true_divide(tracks['major_nhits'], tracks['nhits'])\n",
    "    purity_maj = np.true_divide(tracks['major_nhits'], tracks['major_particle_nhits'])\n",
    "    good_track = (0.5 < purity_rec) & (0.5 < purity_maj)\n",
    "    return tracks['major_weight'][good_track].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get final cluster scores\n",
    "\n",
    "avg_score = 0.0\n",
    "nb_samples = 20\n",
    "for i in range(nb_samples):\n",
    "    cl = clusters[0]\n",
    "    print(cl)\n",
    "    hit_ids = np.arange(len(cl))\n",
    "    truth = pandas.DataFrame.from_dict({'particle_id':pid[i].numpy(),\n",
    "                                        'hit_id':hit_ids,\n",
    "                                        'weight':weight[i].numpy()})\n",
    "    submission = pandas.DataFrame.from_dict({'hit_id':hit_ids,\n",
    "                                             'track_id':cl})\n",
    "    score = score_event(truth, submission)\n",
    "    avg_score += score\n",
    "    break\n",
    "print(\"TrackML score: {:.2f}\".format(avg_score / nb_samples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
